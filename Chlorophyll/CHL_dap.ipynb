{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current runtime: ~1.5min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Chlorophyll Data from the Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Developed during [OceanHackWeek 2019](https://oceanhackweek.github.io) by [Ben Storer](https://github.com/bastorer), [Melanie Feen](https://github.com/melaniefeen), and [Chelle Gentemann](https://github.com/cgentemann)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook illustrates how to remotely access chlorophyll data from *OceanData.sci*.\n",
    "\n",
    "In particular, it allows the user to specify\n",
    "* time range of interest\n",
    "* variable of interest\n",
    "* time binning method (daily or 8-day means)\n",
    "* spatial resolution (4km or 9km)\n",
    "\n",
    "The data is loaded lazily into xarray. This means that data is only transferred to the local machine when it is need, which reduces memory requirements, but does of course mean that thing will take a bit longer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other notebooks\n",
    "\n",
    "* [This notebook](CHL_dap_trim_read.ipynb) allows you to subset the data *before* doing any operations. This allows the user to consider a larger time region without encurring the same computational cost.\n",
    "* [This notebook](CHL_SST_gradients.ipynb) works through loading chlorophyll as seas-surface temperature data and then computes spatial gradients.\n",
    "* [This notebook](../Collocation/Match_InSitu.ipynb) compares the kind of chlorophyll data loaded here with similiar data from Saildrones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To begin, load in our packages of choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "import cmocean\n",
    "from pyproj import Proj\n",
    "\n",
    "from AddParallels_and_Meridians import AddParallels_and_Meridians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is only if you use a dark background notebook. Otherwise, comment this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('dark_background')\n",
    "\n",
    "font = {'size' : 16}\n",
    "\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Data Selection\n",
    "\n",
    "* `start_date`: datetime object indicating beginning time for selection. In `'YYYY-MM-DD'` format.\n",
    "* `end_date`: datetime object indicating end time (none-inclusive) for selection. In `'YYYY-MM-DD'` format.\n",
    "* `VAR`: desired variable. Currently only tested for `'CHL'`\n",
    "* `ALG`: associated variable algorithm/method. Currently only tested for `'chl_ocx'`\n",
    "* `BIN`: time-binning period. Currently only accepts `'DAY'` and `'8D'` for dail and 8-day averages, respectively\n",
    "* `SRES`: spatial resolution. Options are `'4km'` and `'9km'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YYYY-MM-DD\n",
    "start_date = np.datetime64('2018-01-01')\n",
    "end_date   = np.datetime64('2018-07-01')\n",
    "num_days = (end_date - start_date).tolist().days\n",
    "\n",
    "# variable to load\n",
    "VAR = 'CHL'\n",
    "\n",
    "# algorithm\n",
    "ALG = 'chl_ocx'\n",
    "\n",
    "# Binning period\n",
    "BIN = '8D'  # DAY, 8D\n",
    "\n",
    "# Spatial resolution\n",
    "SRES = '9km'   # 4km, 9km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a list of URLs and associated times\n",
    "\n",
    "These URLs will then be used to access the requested netcdf datafiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a list of URLs and datetime objects\n",
    "dap_urls = []\n",
    "the_days = []\n",
    "\n",
    "# The base url, which needs a tail piece to points to the specific data file.\n",
    "url_base = \"https://oceandata.sci.gsfc.nasa.gov:443/opendap/MODISA/L3SMI/\"\n",
    "\n",
    "for ii in range(num_days):\n",
    "    \n",
    "    # Determine current date\n",
    "    curr_date = start_date + ii\n",
    "    \n",
    "    curr_year = curr_date.tolist().year\n",
    "    ref_date = np.datetime64('{0:d}-01-01'.format(curr_year))\n",
    "    \n",
    "    day_num = 1 + (curr_date - ref_date).tolist().days\n",
    "    \n",
    "    # We need to change the formatting a bit depending on the binning\n",
    "    do = True\n",
    "    if BIN == 'DAY':\n",
    "        # If we're on daily data, time_str is 'AYYYYDDD'\n",
    "        time_str = 'A{0:d}{1:03d}'.format(curr_year, day_num)\n",
    "    elif BIN == '8D':\n",
    "        # If we're on 8-day data, time_str is 'AYYYYDDDYYYYDDD'\n",
    "        #    where the first YYYYDDD is the start of the averaging\n",
    "        #    period, and the second is the end of the period.\n",
    "        if (day_num - 1) % 8 == 0:\n",
    "            targ_day = day_num + 7\n",
    "            if targ_day > 365:\n",
    "                targ_day = 365\n",
    "            \n",
    "            time_str = 'A{0:d}{1:03d}{2:d}{3:03d}'.format(curr_year, day_num, curr_year, targ_day)\n",
    "        else:\n",
    "            # There isn't an 8D set starting here\n",
    "            do = False\n",
    "    \n",
    "    # Now build the actual URL.\n",
    "    if do:\n",
    "        file_url = url_base + \\\n",
    "                '{0:d}/{1:03d}/{2}'.format(curr_year, day_num, time_str) + \\\n",
    "                '.L3m_{0}_{1}_{2}_{3}'.format(BIN, VAR, ALG, SRES) + \\\n",
    "                '.nc'\n",
    "    \n",
    "        dap_urls += [file_url]\n",
    "        the_days += [curr_date]\n",
    "    \n",
    "print('dap_urls containts {0:d} urls for {1} data.'.format(len(dap_urls), VAR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now load the datasets\n",
    "\n",
    "We don't use `xr.open_mfdataset` because the source datafiles have no time dimension, in addition to having some extraneous variables the cause merging problems.\n",
    "\n",
    "Instead, we simply create a list of datasets, on for each URL, and in the same order as the URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets = [xr.open_dataset(url) \\\n",
    "             for (url,ind) \\\n",
    "             in zip(dap_urls, np.arange(num_days))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the time array corresponding to the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_array = xr.DataArray(the_days, None, 'time', 'time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate each separate dataset into one large dataset with a time dimension. \n",
    "\n",
    "The values of the time dimension will be taken from `time_array`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = xr.concat(data_sets, time_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "We now have the desired dataset 'loaded' into our notebook (recall that it is lazy loading). We can now proceed to analyze the data as we desire!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Time-Longitude Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.chl_ocx.mean(dim=['time', 'lon']).plot()\n",
    "plt.gca().set_yscale('log')\n",
    "plt.gca().set_title('Time and Longitude Mean of Chlorophyll')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Latitude-Longitude Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.chl_ocx.mean(dim=['lat', 'lon']).plot()\n",
    "plt.gca().set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Time-Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Subsetting\n",
    "\n",
    "Plotting the whole globe takes a while, so let's just plot a small regiong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_lb = -125\n",
    "lon_ub = - 35\n",
    "\n",
    "lat_lb = -20\n",
    "lat_ub =  70\n",
    "\n",
    "subs_mean_chl = merged.chl_ocx.sel(lon=slice(lon_lb,lon_ub),lat=slice(lat_ub,lat_lb)).mean(dim='time').data\n",
    "subs_std_chl  = merged.chl_ocx.sel(lon=slice(lon_lb,lon_ub),lat=slice(lat_ub,lat_lb)).std(dim='time').data\n",
    "\n",
    "subs_lon = merged.lon.sel(lon=slice(lon_lb,lon_ub)).data\n",
    "subs_lat = merged.lat.sel(lat=slice(lat_ub,lat_lb)).data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Specify some lat/lon lines to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meridians = np.round(np.linspace(subs_lon.min(), subs_lon.max(), 5))\n",
    "parallels = np.round(np.linspace(subs_lat.min(), subs_lat.max(), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Create map projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = Proj(proj='wag7', lon_0=subs_lon.mean(), lat_0=subs_lat.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Project our grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sLON, sLAT = np.meshgrid(subs_lon, subs_lat)\n",
    "\n",
    "Xp, Yp = proj(sLON, sLAT, inverse=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plotting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridspec_props = dict(wspace = 0.15, hspace = 0.15, left = 0.1, right = 0.95, bottom = 0.1, top = 0.9)\n",
    "\n",
    "rat   = (Xp.max() - Xp.min()) / (Yp.max() - Yp.min())\n",
    "rat  *= (3./1) * (1.2)\n",
    "fig_h = 6.\n",
    "\n",
    "cmap = plt.get_cmap('cmo.algae')\n",
    "cmap.set_bad('gray', 1.)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, sharex=True, figsize=(fig_h*rat, fig_h), gridspec_kw = gridspec_props)\n",
    "\n",
    "q0 = axes[0].pcolormesh(Xp, Yp, subs_mean_chl, norm=colors.LogNorm(vmin=1e-1, vmax=1e1), cmap=cmap)\n",
    "\n",
    "to_plot = subs_std_chl\n",
    "cv = np.nanpercentile(to_plot, 90)\n",
    "q1 = axes[1].pcolormesh(Xp, Yp, to_plot, vmin=0, vmax=cv, cmap=cmap)\n",
    "\n",
    "to_plot = subs_std_chl / (subs_mean_chl + 1e-5)\n",
    "cv = np.nanpercentile(to_plot, 90)\n",
    "q2 = axes[2].pcolormesh(Xp, Yp, to_plot, vmin=0, vmax=cv, cmap=cmap)\n",
    "\n",
    "plt.colorbar(q0, ax=axes[0])\n",
    "plt.colorbar(q1, ax=axes[1])\n",
    "plt.colorbar(q2, ax=axes[2])\n",
    "\n",
    "axes[0].set_title('$log_{10}(\\mu_t(\\mathrm{CHL}_{\\mathrm{ocx}}))$')\n",
    "axes[1].set_title('$\\sigma_t(\\mathrm{CHL}_{\\mathrm{ocx}})$')\n",
    "axes[2].set_title('$\\sigma_t / \\mu_t$')\n",
    "\n",
    "for ax in axes:\n",
    "    AddParallels_and_Meridians(ax, proj, parallels, meridians, subs_lat, subs_lon)\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "for ax in axes[1:]:\n",
    "    ax.set_yticks([])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
