{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated runtime: ~2min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Spatial Gradients\n",
    "## Comparing Chlorophyll with Sea Surface Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook reads in chloropyll data and computes local gradients in the measured values.\n",
    "This process is then repeated with sea surface temperature data.\n",
    "\n",
    "Derivatives are computed using the `FiniteDiff` tool provided in _FiniteDiff.py_, a custom differentiation tool built by Ben Storer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To begin, load in our packages of choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "import cmocean\n",
    "from pyproj import Proj\n",
    "\n",
    "from AddParallels_and_Meridians import AddParallels_and_Meridians\n",
    "from FiniteDiff import FiniteDiff\n",
    "\n",
    "import podaac.podaac as podaac\n",
    "import podaac.podaac_utils as putil\n",
    "p = podaac.Podaac()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is only if you use a dark background notebook. Otherwise, comment this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('dark_background')\n",
    "\n",
    "font = {'size' : 16}\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define gradient function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(field, LAT, ddlat, ddlon):\n",
    "    grad_field = np.zeros(field.shape)\n",
    "    \n",
    "    if (len(field.shape) == 2):\n",
    "        # Compute (and store) the latitudinal derivative\n",
    "        dfdlat = np.ma.dot(ddlat, field)\n",
    "            \n",
    "        # Compute (and store) the longitudinal derivative\n",
    "        dfdlon = np.ma.dot(ddlon, field.T).T\n",
    "            \n",
    "        # grad(f) =  sec(lat) * ddlon(f) * ehat_lon   +   ddlat(f) * ehat_lat\n",
    "        # compute (and store) the magnitude of the gradient\n",
    "        grad_field = np.sqrt(  (dfdlon / np.cos(LAT * np.pi / 180))**2 \\\n",
    "                              + dfdlat**2 )\n",
    "    else:\n",
    "        for Itime in range(field.shape[0]):\n",
    "        \n",
    "            # Compute (and store) the latitudinal derivative\n",
    "            dfdlat = np.ma.dot(ddlat, field[Itime,:,:])\n",
    "            \n",
    "            # Compute (and store) the longitudinal derivative\n",
    "            dfdlon = np.ma.dot(ddlon, field[Itime,:,:].T).T\n",
    "            \n",
    "            # grad(f) =  sec(lat) * ddlon(f) * ehat_lon   +   ddlat(f) * ehat_lat\n",
    "            # compute (and store) the magnitude of the gradient\n",
    "            grad_field[Itime,:,:] = np.sqrt(  (dfdlon / np.cos(LAT * np.pi / 180))**2 \\\n",
    "                                             + dfdlat**2 )\n",
    "            \n",
    "    return grad_field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Data Selection\n",
    "\n",
    "* `start_date`: datetime object indicating beginning time for selection. In `'YYYY-MM-DD'` format.\n",
    "* `end_date`: datetime object indicating end time (none-inclusive) for selection. In `'YYYY-MM-DD'` format.\n",
    "* `VAR`: desired variable. Currently only tested for `'CHL'`\n",
    "* `ALG`: associated variable algorithm/method. Currently only tested for `'chl_ocx'`\n",
    "* `BIN`: time-binning period. Currently only accepts `'DAY'` and `'8D'` for dail and 8-day averages, respectively\n",
    "* `SRES`: spatial resolution. Options are `'4km'` and `'9km'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YYYY-MM-DD\n",
    "start = '2018-04-12'\n",
    "end   = '2018-05-12'\n",
    "#end   = '2018-06-10'\n",
    "\n",
    "start_date = np.datetime64(start)\n",
    "end_date   = np.datetime64(end)\n",
    "num_days = (end_date - start_date).tolist().days\n",
    "\n",
    "# variable to load\n",
    "VAR = 'CHL'\n",
    "\n",
    "# algorithm\n",
    "ALG = 'chl_ocx'\n",
    "\n",
    "# Binning period\n",
    "BIN = '8D'  # DAY, 8D, MO\n",
    "\n",
    "# Spatial resolution\n",
    "SRES = '9km'   # 4km, 9km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a list of URLs and associated times\n",
    "\n",
    "These URLs will then be used to access the requested netcdf datafiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a list of URLs and datetime objects\n",
    "dap_urls = []\n",
    "the_days = []\n",
    "\n",
    "url_base = \"https://oceandata.sci.gsfc.nasa.gov:443/opendap/MODISA/L3SMI/\"\n",
    "\n",
    "for ii in range(num_days):\n",
    "    \n",
    "    curr_date = start_date + ii\n",
    "    \n",
    "    curr_year = curr_date.tolist().year\n",
    "    ref_date = np.datetime64('{0:d}-01-01'.format(curr_year))\n",
    "    \n",
    "    day_num = 1 + (curr_date - ref_date).tolist().days\n",
    "    \n",
    "    # We need to change the formatting a bit depending on the binning\n",
    "    do = True\n",
    "    if BIN == 'DAY':\n",
    "        time_str = 'A{0:d}{1:03d}'.format(curr_year, day_num)\n",
    "    elif BIN == '8D':\n",
    "        if (day_num - 1) % 8 == 0:\n",
    "            targ_day = day_num + 7\n",
    "            if targ_day > 365:\n",
    "                targ_day = 365\n",
    "            \n",
    "            time_str = 'A{0:d}{1:03d}{2:d}{3:03d}'.format(curr_year, day_num, curr_year, targ_day)\n",
    "        else:\n",
    "            # There isn't an 8D set starting here\n",
    "            do = False\n",
    "    \n",
    "    if do:\n",
    "        file_url = url_base + \\\n",
    "                '{0:d}/{1:03d}/{2}'.format(curr_year, day_num, time_str) + \\\n",
    "                '.L3m_{0}_{1}_{2}_{3}'.format(BIN, VAR, ALG, SRES) + \\\n",
    "                '.nc'\n",
    "    \n",
    "        dap_urls += [file_url]\n",
    "        the_days += [curr_date]\n",
    "    \n",
    "print('dap_urls containts {0:d} urls for {1} data.'.format(len(dap_urls), VAR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now load the datasets\n",
    "\n",
    "We don't use `xr.open_mfdataset` because the source datafiles have no time dimension, in addition to having some extraneous variables the cause merging problems.\n",
    "\n",
    "Instead, we simply create a list of datasets, on for each URL, and in the same order as the URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets = [xr.open_dataset(url) \\\n",
    "             for (url,ind) \\\n",
    "             in zip(dap_urls, np.arange(num_days))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the time array corresponding to the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_array = xr.DataArray(the_days, None, 'time', 'time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate each separate dataset into one large dataset with a time dimension. \n",
    "\n",
    "The values of the time dimension will be taken from `time_array`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = xr.concat(data_sets, time_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "We now have the desired dataset 'loaded' into our notebook (recall that it is lazy loading). We can now proceed to analyze the data as we desire!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradients\n",
    "\n",
    "We're going to compute the magnitude of the spatial gradient ($\\left\\lvert\\\\\\nabla\\mathrm{CHL}\\right\\lvert$) at each point in space.\n",
    "\n",
    "To do this, we will need to do a few things in preparation.\n",
    "\n",
    "1. We'll subset the data to reduce the size of the computations. This isn't strictly necessary, but is useful for illustrative purposes.\n",
    "2. We'll need to mask out the NaN values. Since differentiation is computed via a matrix multiplication, NaNs will propagate terribly.\n",
    "3. Compute differentiation matrices for the physical grids (in spherical coordinates)\n",
    "4. Apply the gradient computation and mask the resulting field using the same mask as applied to the original field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Subsetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_lb = - 85\n",
    "lon_ub = - 75\n",
    "\n",
    "lat_lb =    0\n",
    "lat_ub =   10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_chl = merged.chl_ocx.sel( lon = slice(lon_lb,lon_ub) ,\\\n",
    "                               lat = slice(lat_ub,lat_lb)  \\\n",
    "                             ).data\n",
    "\n",
    "subs_lon = merged.lon.sel( lon = slice(lon_lb,lon_ub) ).data\n",
    "subs_lat = merged.lat.sel( lat = slice(lat_ub,lat_lb) ).data\n",
    "\n",
    "sLON, sLAT = np.meshgrid(subs_lon, subs_lat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Masking out the NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_chl = np.ma.masked_where(np.isnan(subs_chl), subs_chl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Prepare differentiation matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddlon_chl = FiniteDiff(subs_lon, 2, uniform=False, spb=False)\n",
    "ddlat_chl = FiniteDiff(subs_lat, 2, uniform=False, spb=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Compute Gradient and Apply Previous Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_chl      = compute_gradient(subs_chl, sLAT, ddlat_chl, ddlon_chl)\n",
    "grad_mean_chl = compute_gradient(np.mean(subs_chl, axis=0), sLAT, ddlat_chl, ddlon_chl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_chl      = np.ma.masked_where(subs_chl.mask, grad_chl)\n",
    "\n",
    "grad_mean_chl = np.ma.masked_where(np.mean(subs_chl,axis=0).mask, grad_mean_chl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare the Different Methods\n",
    "\n",
    "We computed the mean gradient in two different ways: \n",
    "$\\overline{\\left\\lvert\\\\\\nabla\\mathrm{CHL}\\right\\lvert}$ \n",
    "and \n",
    "$\\left\\lvert\\\\\\nabla\\overline{\\mathrm{CHL}}\\right\\lvert$.\n",
    "\n",
    "In a perfect world, these would be the same thing. \n",
    "However, our data has missing points. \n",
    "These points can be missing either because they are over land or because there were clouds, which don't always play well with satellites.\n",
    "\n",
    "The currently implemented differentiation tools treat masked (missing) points as zero.\n",
    "Is this a good idea? No, not really. \n",
    "But getting to this point was very easy. \n",
    "Going past this point will be rather messy.\n",
    "The takeaway is: *don't trust gradient values near the coast!*\n",
    "\n",
    "So, why does the order of averaging matter? \n",
    "Simply put, if we average first, we can fill in some of the cloudy gaps (clouds move!). \n",
    "This avoids the 'setting to zero' issue as much as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12,5), sharey=True)\n",
    "\n",
    "# Colour map, which sets how to fill masked areas\n",
    "cmap = plt.get_cmap('cmo.amp')\n",
    "cmap.set_bad('gray', 1.)\n",
    "\n",
    "# Plot mean(grad(chl))\n",
    "to_plot = np.mean(grad_chl, axis=0)\n",
    "cv = np.percentile(to_plot, 95)\n",
    "q0 = axes[0].pcolormesh(subs_lon, subs_lat, to_plot, vmin=0, vmax=cv, cmap=cmap)\n",
    "\n",
    "# Plot grad(mean(chl))\n",
    "to_plot = grad_mean_chl\n",
    "cv = np.percentile(to_plot, 95)\n",
    "q1 = axes[1].pcolormesh(subs_lon, subs_lat, to_plot, vmin=0, vmax=cv, cmap=cmap)\n",
    "\n",
    "# Add colour bars\n",
    "plt.colorbar(q0, ax = axes[0])\n",
    "plt.colorbar(q1, ax = axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now repeat the above process for SST data\n",
    "\n",
    "We begin by point to an opendap repository and selecting out a data set covering the same time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = ('https://podaac-opendap.jpl.nasa.gov/opendap/hyrax/'\n",
    "       'allData/insitu/L2/saildrone/Baja/saildrone-gen_4-baja'\n",
    "       '_2018-sd1002-20180411T180000-20180611T055959-1_minutes-v1.nc')\n",
    "ds_usv = xr.open_dataset(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_usv2 = ds_usv.isel(trajectory=0).swap_dims({'obs':'time'}).rename({'longitude':'lon','latitude':'lat'})\n",
    "ds_usv_subset = ds_usv2.sel(time=slice(start+'T02', end+'T18')) \n",
    "\n",
    "start_time = pd.to_datetime( str( ds_usv2.time.min().data) ).strftime('%Y-%m-%dT%H:%m:%SZ') \n",
    "end_time   = pd.to_datetime( str( ds_usv2.time.max().data) ).strftime('%Y-%m-%dT%H:%m:%SZ') \n",
    "\n",
    "print('start: ',start_time,'end: ',end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_id = 'PODAAC-GHGMR-4FJ04'  #MUR SST looked up on podaac website\n",
    "dataset_id = 'PODAAC-GHK10-41N01'  #smaller data\n",
    "gresult = p.granule_search(dataset_id=dataset_id,\n",
    "                           start_time=start_time,\n",
    "                           end_time=end_time,\n",
    "                           items_per_page='100')\n",
    "urls = putil.PodaacUtils.mine_opendap_urls_from_granule_search(gresult)\n",
    "urls = [w[:-5] for w in urls]  #remove html from urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sst = xr.open_mfdataset(urls, coords='minimal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Subsetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_sst = ds_sst.analysed_sst.sel( lon = slice(lon_lb, lon_ub) ,\\\n",
    "                                    lat = slice(lat_ub, lat_lb)  \\\n",
    "                                   )\n",
    "\n",
    "subs_lon_sst = ds_sst.lon.sel( lon = slice(lon_lb, lon_ub) ).data\n",
    "subs_lat_sst = ds_sst.lat.sel( lat = slice(lat_ub, lat_lb) ).data\n",
    "\n",
    "sLON_sst, sLAT_sst = np.meshgrid(subs_lon_sst, subs_lat_sst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_sst = subs_sst.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Masking out the NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_sst = np.ma.masked_where(np.isnan(subs_sst), subs_sst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Prepare differentiation matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddlon_sst = FiniteDiff(subs_lon_sst, 2, uniform=False, spb=False)\n",
    "ddlat_sst = FiniteDiff(subs_lat_sst, 2, uniform=False, spb=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Compute Gradient and Apply Previous Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_sst = compute_gradient(subs_sst, sLAT_sst, ddlat_sst, ddlon_sst)\n",
    "\n",
    "grad_mean_sst = compute_gradient(np.mean(subs_sst,axis=0), sLAT_sst, ddlat_sst, ddlon_sst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_sst      = np.ma.masked_where(subs_sst.mask, grad_sst)\n",
    "\n",
    "grad_mean_sst = np.ma.masked_where(np.mean(subs_sst,axis=0).mask, grad_mean_sst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare SST and CHL results\n",
    "\n",
    "Below, we compare the gradients in sea surface temperature (SST) and chlorophyll (CHL)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(12,12), sharey=True, sharex=True)\n",
    "\n",
    "# Colour map, which sets how to fill masked areas\n",
    "cmap_c = plt.get_cmap('cmo.algae')\n",
    "cmap_c.set_bad('gray', 1.)\n",
    "\n",
    "cmap_s = plt.get_cmap('cmo.amp')\n",
    "cmap_s.set_bad('gray', 1.)\n",
    "\n",
    "# Plot mean(chl)\n",
    "to_plot = np.mean(subs_chl, axis=0)\n",
    "cv = np.percentile(to_plot, 90)\n",
    "q00 = axes[0,0].pcolormesh(subs_lon, subs_lat, to_plot, vmin=0, vmax=cv, cmap=cmap_c)\n",
    "\n",
    "# Plot mean(grad(chl))\n",
    "to_plot = np.mean(grad_chl, axis=0)\n",
    "cv = 5#np.percentile(to_plot, 90)\n",
    "q10 = axes[1,0].pcolormesh(subs_lon, subs_lat, to_plot, vmin=0, vmax=cv, cmap=cmap_c)\n",
    "\n",
    "# Plot grad(mean(chl))\n",
    "to_plot = grad_mean_chl\n",
    "cv = 5#np.percentile(to_plot, 90)\n",
    "q20 = axes[2,0].pcolormesh(subs_lon, subs_lat, to_plot, vmin=0, vmax=cv, cmap=cmap_c)\n",
    "\n",
    "# Plot mean(sst)\n",
    "to_plot = np.mean(subs_sst, axis=0) - 273.15  # Kelvin to Celcius\n",
    "q01 = axes[0,1].pcolormesh(subs_lon_sst, subs_lat_sst, to_plot, cmap=cmap_s)\n",
    "\n",
    "# Plot mean(grad(sst))\n",
    "to_plot = np.mean(grad_sst, axis=0)\n",
    "cv = 3#np.percentile(to_plot, 90)\n",
    "q11 = axes[1,1].pcolormesh(subs_lon_sst, subs_lat_sst, to_plot, vmin=0, vmax=cv, cmap=cmap_s)\n",
    "\n",
    "# Plot grad(mean(sst))\n",
    "to_plot = grad_mean_sst\n",
    "#cv = np.percentile(to_plot, 90)\n",
    "q21 = axes[2,1].pcolormesh(subs_lon_sst, subs_lat_sst, to_plot, vmin=0, vmax=cv, cmap=cmap_s)\n",
    "\n",
    "# Add colour bars\n",
    "plt.colorbar(q00, ax = axes[0,0])\n",
    "plt.colorbar(q01, ax = axes[0,1])\n",
    "plt.colorbar(q10, ax = axes[1,0])\n",
    "plt.colorbar(q11, ax = axes[1,1])\n",
    "plt.colorbar(q20, ax = axes[2,0])\n",
    "plt.colorbar(q21, ax = axes[2,1])\n",
    "\n",
    "axes[0,0].set_title('Chlorophyll')\n",
    "axes[0,1].set_title('SST')\n",
    "\n",
    "axes[0,0].set_ylabel('Time Mean')\n",
    "axes[1,0].set_ylabel('Mean of Gradient')\n",
    "axes[2,0].set_ylabel('Gradient of Mean')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
