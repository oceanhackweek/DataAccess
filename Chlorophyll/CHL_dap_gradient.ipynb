{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current runtime: ~1.5min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Chlorophyll Data from the Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook illustrates how to remotely access chlorophyll data from *OceanData.sci*.\n",
    "\n",
    "In particular, it allows the user to specify\n",
    "* time range of interest\n",
    "* variable of interest\n",
    "* time binning method (daily or 8-day means)\n",
    "* spatial resolution (4km or 9km)\n",
    "\n",
    "The data is loaded lazily into xarray. This means that data is only transferred to the local machine when it is need, which reduces memory requirements, but does of course mean that thing will take a bit longer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To begin, load in our packages of choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "import cmocean\n",
    "from pyproj import Proj\n",
    "\n",
    "from AddParallels_and_Meridians import AddParallels_and_Meridians\n",
    "from FiniteDiff import FiniteDiff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is only if you use a dark background notebook. Otherwise, comment this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('dark_background')\n",
    "\n",
    "font = {'size' : 16}\n",
    "\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Data Selection\n",
    "\n",
    "* `start_date`: datetime object indicating beginning time for selection. In `'YYYY-MM-DD'` format.\n",
    "* `end_date`: datetime object indicating end time (none-inclusive) for selection. In `'YYYY-MM-DD'` format.\n",
    "* `VAR`: desired variable. Currently only tested for `'CHL'`\n",
    "* `ALG`: associated variable algorithm/method. Currently only tested for `'chl_ocx'`\n",
    "* `BIN`: time-binning period. Currently only accepts `'DAY'` and `'8D'` for dail and 8-day averages, respectively\n",
    "* `SRES`: spatial resolution. Options are `'4km'` and `'9km'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YYYY-MM-DD\n",
    "start_date = np.datetime64('2018-01-01')\n",
    "end_date   = np.datetime64('2018-02-01')\n",
    "num_days = (end_date - start_date).tolist().days\n",
    "\n",
    "# variable to load\n",
    "VAR = 'CHL'\n",
    "\n",
    "# algorithm\n",
    "ALG = 'chl_ocx'\n",
    "\n",
    "# Binning period\n",
    "BIN = '8D'  # DAY, 8D, MO\n",
    "\n",
    "# Spatial resolution\n",
    "SRES = '9km'   # 4km, 9km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a list of URLs and associated times\n",
    "\n",
    "These URLs will then be used to access the requested netcdf datafiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a list of URLs and datetime objects\n",
    "dap_urls = []\n",
    "the_days = []\n",
    "\n",
    "url_base = \"https://oceandata.sci.gsfc.nasa.gov:443/opendap/MODISA/L3SMI/\"\n",
    "\n",
    "for ii in range(num_days):\n",
    "    \n",
    "    curr_date = start_date + ii\n",
    "    \n",
    "    curr_year = curr_date.tolist().year\n",
    "    ref_date = np.datetime64('{0:d}-01-01'.format(curr_year))\n",
    "    \n",
    "    day_num = 1 + (curr_date - ref_date).tolist().days\n",
    "    \n",
    "    # We need to change the formatting a bit depending on the binning\n",
    "    do = True\n",
    "    if BIN == 'DAY':\n",
    "        time_str = 'A{0:d}{1:03d}'.format(curr_year, day_num)\n",
    "    elif BIN == '8D':\n",
    "        if (day_num - 1) % 8 == 0:\n",
    "            targ_day = day_num + 7\n",
    "            if targ_day > 365:\n",
    "                targ_day = 365\n",
    "            \n",
    "            time_str = 'A{0:d}{1:03d}{2:d}{3:03d}'.format(curr_year, day_num, curr_year, targ_day)\n",
    "        else:\n",
    "            # There isn't an 8D set starting here\n",
    "            do = False\n",
    "    \n",
    "    if do:\n",
    "        file_url = url_base + \\\n",
    "                '{0:d}/{1:03d}/{2}'.format(curr_year, day_num, time_str) + \\\n",
    "                '.L3m_{0}_{1}_{2}_{3}'.format(BIN, VAR, ALG, SRES) + \\\n",
    "                '.nc'\n",
    "    \n",
    "        dap_urls += [file_url]\n",
    "        the_days += [curr_date]\n",
    "    \n",
    "print('dap_urls containts {0:d} urls for {1} data.'.format(len(dap_urls), VAR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now load the datasets\n",
    "\n",
    "We don't use `xr.open_mfdataset` because the source datafiles have no time dimension, in addition to having some extraneous variables the cause merging problems.\n",
    "\n",
    "Instead, we simply create a list of datasets, on for each URL, and in the same order as the URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets = [xr.open_dataset(url) \\\n",
    "             for (url,ind) \\\n",
    "             in zip(dap_urls, np.arange(num_days))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the time array corresponding to the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_array = xr.DataArray(the_days, None, 'time', 'time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate each separate dataset into one large dataset with a time dimension. \n",
    "\n",
    "The values of the time dimension will be taken from `time_array`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = xr.concat(data_sets, time_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "We now have the desired dataset 'loaded' into our notebook (recall that it is lazy loading). We can now proceed to analyze the data as we desire!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Subsetting\n",
    "\n",
    "Plotting the whole globe takes a while, so let's just plot a small regiong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_lb = -125\n",
    "lon_ub = - 35\n",
    "\n",
    "lat_lb = -20\n",
    "lat_ub =  70\n",
    "\n",
    "subs_chl = merged.chl_ocx.sel(lon=slice(lon_lb,lon_ub),lat=slice(lat_ub,lat_lb)).data\n",
    "\n",
    "subs_lon = merged.lon.sel(lon=slice(lon_lb,lon_ub)).data\n",
    "subs_lat = merged.lat.sel(lat=slice(lat_ub,lat_lb)).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_chl = np.ma.masked_where(np.isnan(subs_chl), subs_chl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_chl[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sLON, sLAT = np.meshgrid(subs_lon, subs_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddlon = FiniteDiff(subs_lon, 2, uniform=False, spb=False)\n",
    "ddlat = FiniteDiff(subs_lat, 2, uniform=False, spb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(field, LAT):\n",
    "    grad_field = np.zeros(field.shape)\n",
    "    \n",
    "    for Itime in range(field.shape[0]):\n",
    "            dfdlat = np.ma.dot(ddlat, field[Itime,:,:])\n",
    "            dfdlon = np.ma.dot(ddlon, field[Itime,:,:].T).T\n",
    "            \n",
    "            grad_field[Itime,:,:] = dfdlon\n",
    "            #grad_field[Itime,:,:] = np.sqrt( (dfdlon / np.cos(LAT * np.pi / 180))**2 + dfdlat**2 )\n",
    "            \n",
    "    return grad_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chl_mean = np.nanmean(subs_chl, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_chl = compute_gradient(subs_chl, sLAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_chl = np.ma.masked_where(subs_chl.mask, grad_chl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(subs_lon, subs_lat, np.mean(grad_chl, axis=0), vmin=-2, vmax=2)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(subs_lon, subs_lat, grad_chl[0,:,:], vmin=-2, vmax=2)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.isnan(grad_chl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.ravel(grad_chl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
