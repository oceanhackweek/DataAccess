{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [SC57 - Working with big, multi-dimensional geoscientific datasets in Python: a tutorial introduction to xarray](http://meetingorganizer.copernicus.org/EGU2017/session/25651)  \n",
    "  \n",
    "  \n",
    "Original notebook by [Stephan Hoyer](http://stephanhoyer.com), Rossbypalooza, 2016.  \n",
    "\n",
    "Edits by Edward Byers, Matthew Gidden and [Fabien Maussion](http://fabienmaussion.info/) for EGU General Assembly 2017, Vienna, Austria,  [Dr Chelle Gentemann](mailto:gentemann@esr.org), Earth and Space Research, USA and [Dr Marisol Garcia-Reyes](mailto:marisolgr@faralloninstitute.org) (multiple events) with help from @lewismc, [B.Storer](https://github.com/bastorer), and [M.Feen](https://github.com/melaniefeen)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure of this tutorial\n",
    "\n",
    "1. Opening data\n",
    "1. Collocating satellite data with a cruise dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Key features of `xarray`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "-------------------\n",
    "\n",
    "## Import python packages\n",
    "\n",
    "You are going to want numpy, pandas, matplotlib.pyplot and xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore') # filter some warning messages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import cmocean\n",
    "from pyproj import Proj\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "\n",
    "#for search capabilites import podaacpy\n",
    "import podaac.podaac as podaac\n",
    "import podaac.podaac_utils as putil\n",
    "# then create an instance of the Podaac class\n",
    "p = podaac.Podaac()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A nice cartopy tutorial is [here](http://earthpy.org/tag/visualization.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collocate a Saildrone cruise with Satellite Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Saildrone cruise is 2 months long."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`xarray`can open multiple files at once using string pattern matching.  \n",
    "  \n",
    "  In this case we open all the files that match our `filestr`, i.e. all the files for the 2080s. \n",
    "  \n",
    "  Each of these files (compressed) is approximately 800 MB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the Saildrone data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://podaac-opendap.jpl.nasa.gov/opendap/hyrax/allData/insitu/L2/saildrone/Baja/saildrone-gen_4-baja_2018-sd1002-20180411T180000-20180611T055959-1_minutes-v1.nc'\n",
    "ds_usv = xr.open_dataset(url)\n",
    "#ds_usv #uncomment this line for information about the data (dimensions, data variables, attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The next section requires a manual input with the start and end time manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_start_time = '2018-04-12'\n",
    "str_end_time = '2018-06-10'\n",
    "str_start_time = '2018-04-12T02'\n",
    "str_end_time = '2018-06-10T18'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset the Saildrone data using the time inputs from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_usv2 = ds_usv.isel(trajectory=0).swap_dims({'obs':'time'}).rename({'longitude':'lon','latitude':'lat'})\n",
    "ds_usv_subset = ds_usv2.sel(time=slice(str_start_time,str_end_time)) \n",
    "start_time=pd.to_datetime(str(ds_usv2.time.min().data)).strftime('%Y-%m-%dT%H:%m:%SZ') \n",
    "end_time=pd.to_datetime(str(ds_usv2.time.max().data)).strftime('%Y-%m-%dT%H:%m:%SZ') \n",
    "ds_usv_subset \n",
    "print('start: ',start_time,'end: ',end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logchl = np.log(ds_usv_subset.CHLOR_MEAN) #take the log of the chlorophyll data\n",
    "\n",
    "#plot the saildrone cruise track colored by the chlorophyll data\n",
    "font = {'size' : 16}\n",
    "plt.rc('font', **font)\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "cs1 = ax.scatter(ds_usv_subset.lon, ds_usv_subset.lat, s=3.0, c=logchl, edgecolor='none', cmap='jet')\n",
    "ax.coastlines()\n",
    "x1,x2,y1,y2 = -128,-112,25,40\n",
    "ax.set_xlim(x1,x2)\n",
    "ax.set_ylim(y1,y2)\n",
    "ax.set_xticks(np.arange(x1,x2,4))\n",
    "ax.set_yticks(np.arange(y1,y2,5))\n",
    "cax = plt.colorbar(cs1)\n",
    "cax.set_label('Mean Log Chlorophyll')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Collocate with Ocean Color Observations from the Ocean Color Web Opendap \n",
    "https://oceandata.sci.gsfc.nasa.gov/opendap/.\n",
    "\n",
    "## This example pulls chlorophyll from MODIS Aqua Level 3 Standard Mapped Image Product.\n",
    "\n",
    "The next section requires manual inputs from the user to build a url to call data from the Opendap. Inputs include the following:\n",
    "* start and end dates (start_date, end_date)\n",
    "* Variable (VAR)\n",
    "* Algorithm (ALG)\n",
    "* Binning period (BIN)\n",
    "* Spatial resolution (SRES)\n",
    "\n",
    "\n",
    "To run just the [tutorial on the Ocean Color data](../Chlorophyll/CHL_dap.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YYYY-MM-DD\n",
    "start_date = np.datetime64(str_start_time[:10])\n",
    "end_date   = np.datetime64(str_end_time[:10])\n",
    "\n",
    "# variable to load\n",
    "VAR = 'CHL'\n",
    "\n",
    "# algorithm\n",
    "ALG = 'chl_ocx'\n",
    "\n",
    "# Binning period\n",
    "BIN = '8D'  # DAY, 8D, MO, R32\n",
    "\n",
    "# Spatial resolution\n",
    "SRES = '9km'   # 4km, 9km\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_days = (end_date - start_date).tolist().days\n",
    "\n",
    "# Track which days are kept\n",
    "the_days = []\n",
    "\n",
    "dap_urls = []\n",
    "\n",
    "url_base = \"https://oceandata.sci.gsfc.nasa.gov:443/opendap/MODISA/L3SMI/\"\n",
    "\n",
    "\n",
    "for ii in range(num_days):\n",
    "    \n",
    "    curr_date = start_date + ii\n",
    "    \n",
    "    curr_year = curr_date.tolist().year\n",
    "    ref_date = np.datetime64('{0:d}-01-01'.format(curr_year))\n",
    "    \n",
    "    day_num = 1 + (curr_date - ref_date).tolist().days\n",
    "    \n",
    "    # We need to change the formatting a bit depending on the binning\n",
    "    do = True\n",
    "    if BIN == 'DAY':\n",
    "        time_str = 'A{0:d}{1:03d}'.format(curr_year, day_num)\n",
    "    elif BIN == '8D':\n",
    "        if (int(day_num) - 1) % 8 == 0:\n",
    "            targ_day = day_num + 7\n",
    "            if targ_day > 365:\n",
    "                targ_day = 365\n",
    "            \n",
    "            time_str = 'A{0:d}{1:03d}{2:d}{3:03d}'.format(curr_year, day_num, curr_year, targ_day)\n",
    "        else:\n",
    "            # There isn't an 8D set starting here\n",
    "            do = False\n",
    "    \n",
    "    if do:\n",
    "        file_url = url_base + \\\n",
    "                '{0:d}/{1:03d}/{2}'.format(curr_year, day_num, time_str) + \\\n",
    "                '.L3m_{0}_{1}_{2}_{3}'.format(BIN, VAR, ALG, SRES) + \\\n",
    "                '.nc'\n",
    "    \n",
    "        dap_urls += [file_url]\n",
    "        \n",
    "        the_days += [curr_date]\n",
    "    \n",
    "print('dap_urls containts {0:d} urls for {1} data.'.format(len(dap_urls), VAR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test that the file you generate actually opens data by loading one time point\n",
    "single_set = xr.open_dataset(dap_urls[0])\n",
    "\n",
    "#and plot the data to see what it looks like!\n",
    "single_set.chl_ocx.plot(\n",
    "    x=\"lon\",\n",
    "    y=\"lat\",\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Satellite Sea Surface Temperature Data\n",
    "\n",
    "### This tutorial originally used Multiscale Ultrahigh Resolution (MUR) SST, which is 0.01 degree resolution, but was updated to pull a daily product by NAVOCEANO on a 0.1 degree grid to increase run time! More information on the product can be found [here](https://cmr.earthdata.nasa.gov/search/concepts/C1268959235-PODAAC.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_id = 'PODAAC-GHGMR-4FJ04'  #MUR SST looked up on podaac website\n",
    "dataset_id = 'PODAAC-GHK10-41N01'  #smaller data\n",
    "gresult = p.granule_search(dataset_id=dataset_id,\n",
    "                           start_time=start_time,\n",
    "                           end_time=end_time,\n",
    "                           items_per_page='100')\n",
    "urls = putil.PodaacUtils.mine_opendap_urls_from_granule_search(gresult)\n",
    "urls = [w[:-5] for w in urls]  #remove html from urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sst = xr.open_mfdataset(urls,coords='minimal')\n",
    "ds_sst\n",
    "\n",
    "ds_sst.analysed_sst[0, ...].plot(\n",
    "    x=\"lon\",\n",
    "    y=\"lat\",\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How big is all this data uncompressed? Will it fit into memory?\n",
    "Use `.nbytes` / 1e9  to convert it into gigabytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sst.nbytes / 1e9  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The NCEI trajectory format uses 'obs' as the coordinate.  This is an example of an 'older' style of data formatting that doesn't really mesh well with modern software capabilities. \n",
    "\n",
    "* So, let's change that by using [.swap_dims](http://xarray.pydata.org/en/stable/generated/xarray.DataArray.swap_dims.html) to change the coordinate from `obs` to `time`\n",
    "* Another thing, `latitude` and `longitude` are just long and annoying, lets [.rename](http://xarray.pydata.org/en/stable/generated/xarray.Dataset.rename.html) them to `lat` and `lon`\n",
    "\n",
    "* Finally, the first and last part of the cruise the USV is being towed, so let's only include data from `2018-04-12T02` to `2018-06-10T18`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xarray interpolation won't run on chunked dimensions.  \n",
    "1. First let's subset the data to make it smaller to deal with by using the cruise lat/lons\n",
    "    * Find the max/min of the lat/lon using `.lon.min().data`\n",
    "\n",
    "1. Now load the data into memory (de-Dask-ify) it using `.load()`  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1 from above - this takes the lat and lon from the saildrone data and subsets the satellite sst\n",
    "print('min max lat lon:', ds_usv_subset.lon.min().data,ds_usv_subset.lon.max().data,ds_usv_subset.lat.min().data,ds_usv_subset.lat.max().data)\n",
    "lon_min,lon_max = ds_usv_subset.lon.min().data,ds_usv_subset.lon.max().data\n",
    "lat_min,lat_max = ds_usv_subset.lat.min().data,ds_usv_subset.lat.max().data\n",
    "subset_sat_sst = ds_sst.sel(lon=slice(lon_min,lon_max),\n",
    "                  lat=slice(lat_max,lat_min))\n",
    "\n",
    "#subset_sat_sst #uncomment this line for info on the dimensions and variables in the satellite sst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the satellite SST subset\n",
    "\n",
    "xv, yv = np.meshgrid(subset_sat_sst.lon, subset_sat_sst.lat)\n",
    "font = {'size' : 16}\n",
    "plt.rc('font', **font)\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "cs1 = ax.scatter(xv, yv, s=3.0, c=subset_sat_sst.analysed_sst[0,:,:], edgecolor='none', cmap='jet')\n",
    "ax.coastlines()\n",
    "x1,x2,y1,y2 = -128,-112,25,40\n",
    "ax.set_xlim(x1,x2)\n",
    "ax.set_ylim(y1,y2)\n",
    "ax.set_xticks(np.arange(x1,x2,4))\n",
    "ax.set_yticks(np.arange(y1,y2,5))\n",
    "cax = plt.colorbar(cs1)\n",
    "cax.set_label('SST (kelvin)')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is now subsetting the ocean color satellite data\n",
    "def preprocess_set(dset, time):\n",
    "    return dset.sel(lon=slice(lon_min,lon_max),lat=slice(lat_max,lat_min))\n",
    "\n",
    "data_sets = [preprocess_set(xr.open_dataset(url), ind) \\\n",
    "             for (url,ind) \\\n",
    "             in zip(dap_urls, np.arange(num_days))]\n",
    "\n",
    "time_array = xr.DataArray(the_days, None, 'time', 'time')\n",
    "\n",
    "subset_chl = xr.concat(data_sets, time_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2 from above - load in the data subsets\n",
    "subset_sat_sst.load()\n",
    "subset_chl.load()\n",
    "print() #comment this line for some output, but this keeps the work space nice and neat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the subset of chlorophyll satellite data\n",
    "\n",
    "xv2, yv2 = np.meshgrid(subset_chl.lon, subset_chl.lat)\n",
    "\n",
    "font = {'size' : 16}\n",
    "plt.rc('font', **font)\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "cs1 = ax.scatter(xv2, yv2, s=3.0, c=(np.log(subset_chl.chl_ocx[0,:,:])), edgecolor='none', cmap='jet')\n",
    "ax.coastlines()\n",
    "x1,x2,y1,y2 = -128,-112,25,40\n",
    "ax.set_xlim(x1,x2)\n",
    "ax.set_ylim(y1,y2)\n",
    "ax.set_xticks(np.arange(x1,x2,4))\n",
    "ax.set_yticks(np.arange(y1,y2,5))\n",
    "cax = plt.colorbar(cs1)\n",
    "cax.set_label('Log Chl (mg/m^3)')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collocate In Situ USV data with the Satellite SST data and Ocean Color Data\n",
    "There are different options when you interpolate.  First, let's just do a linear interpolation using [.interp()](http://xarray.pydata.org/en/stable/generated/xarray.Dataset.interp.html#xarray.Dataset.interp)\n",
    "\n",
    "`Dataset.interp(coords=None, method='linear', assume_sorted=False, kwargs={}, **coords_kwargs))`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure they both have the same time stamp format otherwise the interpolation will fail\n",
    "subset_sat_sst['time'] = subset_sat_sst.indexes['time'].to_datetimeindex()\n",
    "#subset_sat_sst.time #uncomment this line to see that the satellite SST date format is correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_collocated_sst = subset_sat_sst.interp(lat=ds_usv_subset.lat,lon=ds_usv_subset.lon,time=ds_usv_subset.time,method='linear')\n",
    "ds_collocated_oc = subset_chl.interp(lat=ds_usv_subset.lat,lon=ds_usv_subset.lon,time=ds_usv_subset.time,method='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif_sst_lin = ds_collocated_sst.analysed_sst-(ds_usv_subset.TEMP_CTD_MEAN + 273.15)\n",
    "print('mean difference = ',dif_sst_lin.mean().data)\n",
    "print('STD = ',dif_sst_lin.std().data)\n",
    "\n",
    "dif_oc_lin = ds_collocated_oc.chl_ocx-ds_usv_subset.CHLOR_MEAN\n",
    "print('mean difference = ',dif_oc_lin.mean().data)\n",
    "print('STD = ',dif_oc_lin.std().data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collocate USV data with SST data\n",
    "There are different options when you interpolate.  First, let's just do a nearest point rather than interpolate the data\n",
    "`method = 'nearest'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_collocated_nearest_sst = subset_sat_sst.interp(lat=ds_usv_subset.lat,lon=ds_usv_subset.lon,time=ds_usv_subset.time,method='nearest')\n",
    "ds_collocated_nearest_oc = subset_chl.interp(lat=ds_usv_subset.lat,lon=ds_usv_subset.lon,time=ds_usv_subset.time,method='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, calculate the different in SSTs and print the [.mean()](http://xarray.pydata.org/en/stable/generated/xarray.DataArray.mean.html#xarray.DataArray.mean) and [.std()](http://xarray.pydata.org/en/stable/generated/xarray.DataArray.std.html#xarray.DataArray.std)\n",
    "For the satellite data we need to use `sst` and for the USV data we need to use `TEMP_CTD_MEAN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_collocated_nearest_sst.analysed_sst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_usv_subset.TEMP_CTD_MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif_sst_near = ds_collocated_nearest_sst.analysed_sst-(ds_usv_subset.TEMP_CTD_MEAN + 273.15)\n",
    "print('mean difference = ',dif_sst_near.mean().data)\n",
    "print('STD = ',dif_sst_near.std().data)\n",
    "\n",
    "dif_oc_near = ds_collocated_nearest_oc.chl_ocx-ds_usv_subset.CHLOR_MEAN\n",
    "print('mean difference = ',dif_oc_near.mean().data)\n",
    "print('STD = ',dif_oc_near.std().data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12,14),sharey = True,subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "plt.rc('font', **font)\n",
    "ax=axes[0,0]\n",
    "cs00 = axes[0,0].scatter(ds_usv_subset.lon, ds_usv_subset.lat, s=3.0, c=logchl, edgecolor='none', cmap='cmo.algae')\n",
    "ax.coastlines()\n",
    "cax = plt.colorbar(cs00,ax=axes[0,0])\n",
    "cax.set_label('Log Mean Chlorophyll (mg/m^3)')\n",
    "ax.set_title('Saildrone')\n",
    "\n",
    "\n",
    "\n",
    "#plot the satellite cruise track colored by the chlorophyll data\n",
    "plt.rc('font', **font)\n",
    "ax =axes[0,1]\n",
    "cs01 = ax.scatter(ds_usv_subset.lon, ds_usv_subset.lat, s=3.0, c=ds_collocated_nearest_oc.chl_ocx, edgecolor='none', cmap='cmo.algae')\n",
    "ax.coastlines()\n",
    "cax = plt.colorbar(cs01,ax=axes[0,1])\n",
    "cax.set_label('Mean Log Chlorophyll (mg/m^3)')\n",
    "ax.set_title('Satellite')\n",
    "\n",
    "\n",
    "#plot the satellite cruise track colored by the chlorophyll data\n",
    "plt.rc('font', **font)\n",
    "ax =axes[1,0]\n",
    "cv=np.percentile(np.abs(dif_oc_lin),75)\n",
    "cs10 = ax.scatter(ds_usv_subset.lon, ds_usv_subset.lat, s=3.0, c=dif_oc_lin, edgecolor='none', cmap='cmo.balance',vmin=-cv,vmax=cv)\n",
    "ax.coastlines()\n",
    "cax = plt.colorbar(cs10,ax=axes[1,0])\n",
    "cax.set_label('Difference')\n",
    "ax.set_title('Linear Interpolation (mg/m^3)')\n",
    "\n",
    "#plot the satellite cruise track colored by the chlorophyll data\n",
    "plt.rc('font', **font)\n",
    "ax = axes[1,1]\n",
    "cv=np.percentile(np.abs(dif_oc_near),75)\n",
    "cs11 = ax.scatter(ds_usv_subset.lon, ds_usv_subset.lat, s=3.0, c=dif_oc_near, edgecolor='none', cmap='cmo.balance',vmin=-cv,vmax=cv)\n",
    "ax.coastlines()\n",
    "cax = plt.colorbar(cs11,ax=axes[1,1])\n",
    "cax.set_label('Difference')\n",
    "ax.set_title('Nearest Neighbor (mg/m^3)')\n",
    "\n",
    "for ax in axes.ravel():\n",
    "    x1,x2,y1,y2 = -128,-112,25,40\n",
    "    ax.set_xlim(x1,x2)\n",
    "    ax.set_ylim(y1,y2)\n",
    "    ax.set_xticks(np.arange(x1,x2,4))\n",
    "    ax.set_yticks(np.arange(y1,y2,5))\n",
    "    font = {'size' : 14}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12,14),sharey = True,subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "plt.rc('font', **font)\n",
    "ax=axes[0,0]\n",
    "cs00 = axes[0,0].scatter(ds_usv_subset.lon, ds_usv_subset.lat, s=3.0, c=ds_usv_subset.TEMP_CTD_MEAN + 273.15, edgecolor='none', cmap='cmo.tempo')\n",
    "ax.coastlines()\n",
    "cax = plt.colorbar(cs00,ax=axes[0,0])\n",
    "cax.set_label('Temperature (degC)')\n",
    "ax.set_title('Saildrone')\n",
    "\n",
    "\n",
    "\n",
    "plt.rc('font', **font)\n",
    "ax =axes[0,1]\n",
    "cs01 = ax.scatter(ds_usv_subset.lon, ds_usv_subset.lat, s=3.0, c=ds_collocated_nearest_sst.analysed_sst, edgecolor='none', cmap='cmo.tempo')\n",
    "ax.coastlines()\n",
    "cax = plt.colorbar(cs01,ax=axes[0,1])\n",
    "cax.set_label('Temperature(degC)')\n",
    "ax.set_title('Satellite')\n",
    "\n",
    "\n",
    "plt.rc('font', **font)\n",
    "ax =axes[1,0]\n",
    "cv=np.percentile(np.abs(dif_oc_lin),75)\n",
    "cs10 = ax.scatter(ds_usv_subset.lon, ds_usv_subset.lat, s=3.0, c=dif_sst_lin, edgecolor='none', cmap='cmo.balance',vmin=-cv,vmax=cv)\n",
    "ax.coastlines()\n",
    "cax = plt.colorbar(cs10,ax=axes[1,0])\n",
    "cax.set_label('Difference')\n",
    "ax.set_title('Linear Interpolation (degC)')\n",
    "\n",
    "plt.rc('font', **font)\n",
    "ax = axes[1,1]\n",
    "cv=np.percentile(np.abs(dif_oc_near),75)\n",
    "cs11 = ax.scatter(ds_usv_subset.lon, ds_usv_subset.lat, s=3.0, c=dif_sst_near, edgecolor='none', cmap='cmo.balance',vmin=-cv,vmax=cv)\n",
    "ax.coastlines()\n",
    "cax = plt.colorbar(cs11,ax=axes[1,1])\n",
    "cax.set_label('Difference')\n",
    "ax.set_title('Nearest Neighbor (degC)')\n",
    "\n",
    "for ax in axes.ravel():\n",
    "    x1,x2,y1,y2 = -128,-112,25,40\n",
    "    ax.set_xlim(x1,x2)\n",
    "    ax.set_ylim(y1,y2)\n",
    "    ax.set_xticks(np.arange(x1,x2,4))\n",
    "    ax.set_yticks(np.arange(y1,y2,5))\n",
    "    font = {'size' : 14}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
